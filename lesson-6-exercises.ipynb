{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chains: some work with text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pride_and_prejudice.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#import numpy as np\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# first, read the text file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# change encoding to utf-8-sig, otherwise it will add a Byte order mark (BOM, a unicode symbol) in the beginning of the file!\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpride_and_prejudice.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m,  encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m     book \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(book)\n",
      "File \u001b[1;32mc:\\Users\\Debashish Sen\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pride_and_prejudice.txt'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# first, read the text file\n",
    "# change encoding to utf-8-sig, otherwise it will add a Byte order mark (BOM, a unicode symbol) in the beginning of the file!\n",
    "with open('pride_and_prejudice.txt',mode='r',  encoding='utf-8-sig') as f:\n",
    "    book = f.read()\n",
    "    \n",
    "print(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import itertools\n",
    "\n",
    "# let's remove some the text in the beginning and leave only the actual text of the book. \n",
    "normal_words = book.split()[105:]\n",
    "\n",
    "# add dots\n",
    "for i in range(len(normal_words)):\n",
    "    if '.' in normal_words[i] and len(normal_words[i]) > 1:\n",
    "        normal_words[i] = normal_words[i].replace(\".\", \"\")\n",
    "        normal_words.insert(i+1, '.')\n",
    "\n",
    "# and also remove some text in the end\n",
    "normal_words = normal_words[:len(normal_words)-2926]\n",
    "\n",
    "print(normal_words[len(normal_words)-10:len(normal_words)])\n",
    "\n",
    "\n",
    "# define the vector of states (unique words)\n",
    "# use this and not SET to preserve the order! \n",
    "states = list(OrderedDict.fromkeys(normal_words).keys())\n",
    "\n",
    "print(len(normal_words))\n",
    "print(len(states))\n",
    "states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary where keys are the actual words and values are the integer labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# enumrate the states\n",
    "labs = np.arange(0, len(states))\n",
    "\n",
    "# turn the sequence of words into a sequence of integers, and map them together into a dictionary\n",
    "res = {states[i]: labs[i] for i in range(len(labs))}\n",
    "\n",
    "print(res.values())\n",
    "res.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a method for mapping the words into integers and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_words_into_integers(normal_words):\n",
    "    mapped_words = []\n",
    "\n",
    "    for cur_word in normal_words:\n",
    "        cur_ind = list(res.keys()).index(cur_word)\n",
    "        mapped_words.append(list(res.values())[cur_ind])\n",
    "        \n",
    "    return mapped_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_integers_into_words(integers):\n",
    "    real_words = []\n",
    "\n",
    "    for cur_word in integers:\n",
    "        cur_ind = list(res.values()).index(cur_word)\n",
    "        real_words.append(list(res.keys())[cur_ind])\n",
    "        \n",
    "    return real_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and define a method to create transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(chain_seq):\n",
    "    # define number of states\n",
    "    n = 1+ max(chain_seq) \n",
    "    # create an empty nXn matrix, which we will fill in\n",
    "    M = np.zeros((n,n))\n",
    "    # zip is a useful method for working with matrices\n",
    "    # for each states, we add up to a matrix whenever we find this state in the sequence \n",
    "    for (i,j) in zip(chain_seq,chain_seq[1:]):\n",
    "        M[i][j] += 1\n",
    "\n",
    "    #now convert to probabilities:\n",
    "    M = M/M.sum(axis=1, keepdims=True)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the function: first, make integers out of words (might take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function: first, make integers out of words (might take a while)\n",
    "\n",
    "words_mapped = map_words_into_integers(normal_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_words = transition_matrix(words_mapped)\n",
    "\n",
    "# check the sum across rows, should be one!\n",
    "p_words.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate samplings of your own text using the estimated probability matrix! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def generate_and_write(p_words, init_state, filename):\n",
    "\n",
    "    def generate_text(states, p_words, init_state):\n",
    "\n",
    "        # generate some text with N words\n",
    "        N = 500\n",
    "\n",
    "        # for the current word, generate the new word k times and choose the most common one\n",
    "        k = 10\n",
    "\n",
    "        n_states = len(states)\n",
    "        # p_words is the matrix\n",
    "\n",
    "        # initial state:\n",
    "        i1 = init_state\n",
    "        all_words = [i1]\n",
    "        for i in range(1, N):\n",
    "            # all words generated k times for the current state\n",
    "            cur_states_word = []\n",
    "            # given the current state, choose the column of the matrix accordingly \n",
    "            p_column = p_words[all_words[i-1]]\n",
    "            # generate k words according to the matrix\n",
    "            for j in range(k):\n",
    "                cur_states_word.append(np.random.choice(np.arange(0, n_states), p = p_column))\n",
    "                \n",
    "            # now choose the most common word\n",
    "            most_common_word = list(Counter(cur_states_word).most_common(1)[0])[0]\n",
    "            all_words.append(most_common_word)\n",
    "            \n",
    "        return all_words\n",
    "\n",
    "\n",
    "    text_integers = generate_text(states, p_words, init_state)\n",
    "    my_text = map_integers_into_words(text_integers)\n",
    "\n",
    "    whole_text = ' '.join(my_text)\n",
    "\n",
    "    with open(filename, \"w\") as text_file:\n",
    "        text_file.write(whole_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now generate text and write into a file\n",
    "generate_and_write(p_words, 0, 'text-generation-attempt.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the file:\n",
    "with open('text-generation-attempt.txt', \"r\") as my_file:\n",
    "    gen_text = my_file.read()\n",
    "\n",
    "print(gen_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic plots in jupiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    " \n",
    " \n",
    "def interactive_plot(amplitude, frequency):\n",
    "    x = np.linspace(0, 2 * np.pi, 10)\n",
    "    y = amplitude * np.sin(frequency * x)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.title('Interactive Sine Wave')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(interactive_plot, amplitude=(1, 5, 0.1), frequency=(1, 10, 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    " \n",
    "\n",
    "some_seq = [1, 2, 1, 3, 4, 10, 3, 2, 1, 6, 20, 1, 2, 3]\n",
    "\n",
    "# make dynamic plot\n",
    "\n",
    "def plot_seq(n):\n",
    "    len_y = n #len(y) if  type(y) == list else 1\n",
    "    x = np.arange(0, len_y)\n",
    "    y = some_seq[0:n]\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('n steps')\n",
    "    plt.ylabel('Process state')\n",
    "    plt.title('Interactive Process plot')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_seq, n = np.arange(0, len(some_seq))) #[some_seq[0:1], some_seq[0:2], some_seq[0:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chain examples: Stationary distribuiton. Recall: pi*M = pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# define some matrix of probabilities\n",
    "transition_matrix = np.array([[0,0.5,0.5],\n",
    "                              [0,0.3,0.7],\n",
    "                              [1,0,0]])\n",
    "\n",
    "# do the rows sum to 1?\n",
    "print(transition_matrix.sum(axis=1))\n",
    "\n",
    "transition_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " No built-in method to find stationary distribution. One of the algorithms:\n",
    " Find the eigenvector with an eigenvalue that is are close to one. To compute the stationary distribution, every element in the selected eigenvector is divided by the sum of the eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the matrix\n",
    "transition_matrix_t = transition_matrix.T\n",
    "# use linear algebra module of numpy to compute the eigenvalues\n",
    "eigenvals, eigenvects = np.linalg.eig(transition_matrix_t)\n",
    "\n",
    "\n",
    "# Find the indexes of the eigenvalues that are close to one.\n",
    "close_to_1_idx = np.isclose(eigenvals,1) # isclose checks element-wise if each element is close to 1 within the specific tolerance\n",
    "# Use them to select the target eigen vectors\n",
    "target_eigenvect = eigenvects[:,close_to_1_idx]\n",
    "#Flatten\n",
    "target_eigenvect = target_eigenvect[:,0]\n",
    "# Turn the eigenvector elements into probabilities\n",
    "# that would be the stationary distribution\n",
    "st_d = target_eigenvect / sum(target_eigenvect) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the real part of the probability\n",
    "print(st_d.real)\n",
    "\n",
    "# our stationary distribution pi\n",
    "real_st_distr = st_d.real\n",
    "\n",
    "# check if they sum to 1\n",
    "st_d.real.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the fixed point equation: pi*M = pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_st_distr.dot(transition_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
