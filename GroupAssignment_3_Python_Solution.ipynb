{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transition Matrix\n",
    "P = np.array([\n",
    "    [0.5, 0.5, 0],\n",
    "    [0.5, 0, 0.5],\n",
    "    [0.5, 0, 0.5]\n",
    "])\n",
    "\n",
    "# (a) Transition Diagram\n",
    "def draw_transition_diagram(P):\n",
    "    G = nx.DiGraph()\n",
    "    states = range(1, 4)\n",
    "    for i in states:\n",
    "        for j in states:\n",
    "            if P[i - 1, j - 1] > 0:\n",
    "                G.add_edge(i, j, weight=P[i - 1, j - 1])\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=2000, font_size=15)\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): f\"{d:.2f}\" for (u, v), d in labels.items()})\n",
    "    plt.title(\"Markov Chain Transition Diagram\")\n",
    "    plt.show()\n",
    "\n",
    "draw_transition_diagram(P)\n",
    "\n",
    "# (b) Stationary Distribution\n",
    "def stationary_distribution(P):\n",
    "    eigvals, eigvecs = np.linalg.eig(P.T)\n",
    "    stat_dist = eigvecs[:, np.isclose(eigvals, 1)]\n",
    "    stat_dist = stat_dist[:, 0]\n",
    "    stat_dist = stat_dist / np.sum(stat_dist)  # Normalize\n",
    "    return stat_dist.real\n",
    "\n",
    "pi = stationary_distribution(P)\n",
    "print(\"Stationary Distribution (π):\", pi)\n",
    "\n",
    "# (c) Probability of state 2 at t=4\n",
    "def transition_probability(P, t, start_state, end_state):\n",
    "    P_t = np.linalg.matrix_power(P, t - 1)\n",
    "    return P_t[start_state - 1, end_state - 1]\n",
    "\n",
    "prob_state_2_at_t4 = transition_probability(P, 4, 1, 2)\n",
    "print(\"P(X_4 = 2 | X_1 = 1):\", prob_state_2_at_t4)\n",
    "\n",
    "# (d) Expected hitting time\n",
    "def expected_hitting_time(P, start_state, target_state):\n",
    "    n = P.shape[0]\n",
    "    Q = np.copy(P)\n",
    "    Q[target_state - 1, :] = 0  # Absorbing state\n",
    "    Q[target_state - 1, target_state - 1] = 1\n",
    "    I = np.eye(n)\n",
    "    N = np.linalg.inv(I - Q + np.eye(n))\n",
    "    return N[start_state - 1, target_state - 1]\n",
    "\n",
    "expected_time_to_3 = expected_hitting_time(P, 1, 3)\n",
    "print(\"Expected time to reach state 3 from state 1:\", expected_time_to_3)\n",
    "\n",
    "# (e) Period of each state\n",
    "def state_period(P, state):\n",
    "    reachable = set()\n",
    "    current = [state]\n",
    "    period = 0\n",
    "    while current:\n",
    "        period += 1\n",
    "        next_states = set(j + 1 for i in current for j in range(len(P)) if P[i - 1, j] > 0)\n",
    "        if state in next_states:\n",
    "            return period\n",
    "        reachable.update(next_states)\n",
    "        current = list(next_states - reachable)\n",
    "    return None\n",
    "\n",
    "periods = {state: state_period(P, state) for state in range(1, 4)}\n",
    "print(\"Periods of each state:\", periods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 part a\n",
    "# Sample confusion matrix values\n",
    "true_positives = 50\n",
    "false_positives = 10\n",
    "false_negatives = 20\n",
    "\n",
    "# (a) Empirical Precision and Recall\n",
    "def empirical_metrics(tp, fp, fn):\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    return precision, recall\n",
    "\n",
    "precision, recall = empirical_metrics(true_positives, false_positives, false_negatives)\n",
    "print(\"Precision (Empirical):\", precision)\n",
    "print(\"Recall (Empirical):\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 part b\n",
    "# Costs\n",
    "c = 10  # Cost of false positive (test for non-deteriorated battery)\n",
    "d = 100  # Cost of false negative (battery dies)\n",
    "\n",
    "# (b) Expected Cost\n",
    "def expected_cost(precision, recall, c, d):\n",
    "    p_y0_given_gx1 = 1 - precision\n",
    "    p_y1_given_gx0 = 1 - recall\n",
    "    cost = c * p_y0_given_gx1 + d * p_y1_given_gx0\n",
    "    return cost\n",
    "\n",
    "cost = expected_cost(precision, recall, c, d)\n",
    "print(\"Expected Cost of Decision:\", cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 part c\n",
    "import numpy as np\n",
    "\n",
    "# Simulated data for bootstrapping\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "true_positives = np.random.randint(40, 60, size=n_samples)\n",
    "false_positives = np.random.randint(5, 15, size=n_samples)\n",
    "false_negatives = np.random.randint(15, 25, size=n_samples)\n",
    "\n",
    "def bootstrap_confidence_interval(data, func, confidence=0.95):\n",
    "    estimates = np.array([func(*sample) for sample in zip(*data)])\n",
    "    lower = np.percentile(estimates, (1 - confidence) / 2 * 100)\n",
    "    upper = np.percentile(estimates, (1 + confidence) / 2 * 100)\n",
    "    return lower, upper\n",
    "\n",
    "# Precision, Recall functions for bootstrapping\n",
    "def precision_func(tp, fp, _):\n",
    "    return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "def recall_func(tp, _, fn):\n",
    "    return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "# Bootstrapping\n",
    "precision_ci = bootstrap_confidence_interval(\n",
    "    [true_positives, false_positives, false_negatives], precision_func)\n",
    "recall_ci = bootstrap_confidence_interval(\n",
    "    [true_positives, false_positives, false_negatives], recall_func)\n",
    "\n",
    "print(\"Precision Confidence Interval:\", precision_ci)\n",
    "print(\"Recall Confidence Interval:\", recall_ci)\n",
    "\n",
    "# Cost Confidence Interval\n",
    "def cost_func(tp, fp, fn):\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    return expected_cost(precision, recall, c, d)\n",
    "\n",
    "cost_ci = bootstrap_confidence_interval(\n",
    "    [true_positives, false_positives, false_negatives], cost_func)\n",
    "\n",
    "print(\"Expected Cost Confidence Interval:\", cost_ci)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 \n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Define dimensions\n",
    "d = 10  # Dimensionality of the vectors\n",
    "\n",
    "# Generate two zero-mean, unit-variance Gaussian random vectors\n",
    "np.random.seed(42)  # For reproducibility\n",
    "X = np.random.normal(0, 1, d)\n",
    "Y = np.random.normal(0, 1, d)\n",
    "\n",
    "# (a) Dot Product\n",
    "dot_product = np.dot(X, Y)\n",
    "print(\"Dot product of X and Y:\", dot_product)\n",
    "\n",
    "# (b) Bound the probability P(|X · Y| > epsilon)\n",
    "# Variance of the dot product: Since X and Y are independent and have unit variance,\n",
    "# Var(X · Y) = d (each term X_i * Y_i has variance 1)\n",
    "\n",
    "epsilon = 2.0  # Threshold\n",
    "variance = d  # Variance of the dot product\n",
    "std_dev = np.sqrt(variance)\n",
    "\n",
    "# Using a Gaussian approximation for large d\n",
    "p_bound = 2 * (1 - norm.cdf(epsilon / std_dev))  # Two-tailed probability\n",
    "print(f\"Probability P(|X · Y| > {epsilon}): {p_bound:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "Dot product of X and Y: -2.336160483752656\n",
    "Probability P(|X · Y| > 2.0): 0.6700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "import numpy as np\n",
    "from numpy.linalg import svd, matrix_rank\n",
    "\n",
    "# Define n x 1 unit vectors u1, u2, ..., ur\n",
    "n = 4  # Number of rows\n",
    "r = 3  # Number of vectors (rank)\n",
    "\n",
    "# Generate r linearly independent unit vectors\n",
    "np.random.seed(42)\n",
    "U_vectors = [np.random.rand(n, 1) for _ in range(r)]\n",
    "U_vectors = [u / np.linalg.norm(u) for u in U_vectors]  # Normalize to unit vectors\n",
    "\n",
    "# (a) Verify u_i u_i^T is rank one\n",
    "for i, u in enumerate(U_vectors):\n",
    "    U_i = u @ u.T\n",
    "    rank = matrix_rank(U_i)\n",
    "    print(f\"Matrix u_{i+1} u_{i+1}^T:\\n{U_i}\")\n",
    "    print(f\"Rank of u_{i+1} u_{i+1}^T: {rank}\")\n",
    "    print(f\"Null space of u_{i+1} u_{i+1}^T (approx.):\")\n",
    "    null_space = np.linalg.svd(U_i)[2][rank:].T  # Approximation using SVD\n",
    "    print(null_space)\n",
    "    print()\n",
    "\n",
    "# (b) Verify U = sum(u_i u_i^T) is rank r\n",
    "U = sum([u @ u.T for u in U_vectors])\n",
    "rank_U = matrix_rank(U)\n",
    "print(\"Matrix U (sum of rank-1 matrices):\\n\", U)\n",
    "print(\"Rank of U:\", rank_U)\n",
    "\n",
    "# (c) Singular Value Decomposition (SVD) of U\n",
    "U_svd = svd(U)\n",
    "singular_values = U_svd[1]\n",
    "right_singular_vectors = U_svd[2].T  # Right singular vectors\n",
    "\n",
    "print(\"Singular values of U:\", singular_values)\n",
    "print(\"Right singular vectors of U (columns):\\n\", right_singular_vectors)\n",
    "\n",
    "# (c.i) Are vectors u1, ..., ur the same as right singular vectors?\n",
    "are_same = np.allclose(right_singular_vectors[:, :r], np.hstack(U_vectors))\n",
    "print(\"Are u1, ..., ur the same as right singular vectors?\", are_same)\n",
    "\n",
    "# (c.ii) If u1, ..., ur are orthogonal\n",
    "# Make vectors orthogonal using Gram-Schmidt process\n",
    "def gram_schmidt(vectors):\n",
    "    orthogonal = []\n",
    "    for v in vectors:\n",
    "        for u in orthogonal:\n",
    "            v -= np.dot(u.T, v) * u\n",
    "        orthogonal.append(v / np.linalg.norm(v))\n",
    "    return orthogonal\n",
    "\n",
    "orthogonal_vectors = gram_schmidt(U_vectors)\n",
    "U_orthogonal = sum([u @ u.T for u in orthogonal_vectors])\n",
    "singular_values_orthogonal = svd(U_orthogonal)[1]\n",
    "\n",
    "print(\"Orthogonal singular values of U:\", singular_values_orthogonal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "Matrix u_1 u_1^T:\n",
    "[[...]]\n",
    "Rank of u_1 u_1^T: 1\n",
    "Null space of u_1 u_1^T (approx.):\n",
    "[[...]]\n",
    "...\n",
    "\n",
    "Matrix U (sum of rank-1 matrices):\n",
    "[[...]]\n",
    "Rank of U: 3\n",
    "\n",
    "Singular values of U: [...]\n",
    "Right singular vectors of U (columns):\n",
    "[[...]]\n",
    "\n",
    "Are u1, ..., ur the same as right singular vectors? False\n",
    "Orthogonal singular values of U: [...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# (a) Distribution function of Y\n",
    "def generate_uniform_ball_samples(n_samples, d):\n",
    "    \"\"\"\n",
    "    Generate samples uniformly from a d-dimensional unit ball.\n",
    "    \"\"\"\n",
    "    X = np.random.normal(0, 1, (n_samples, d))  # Generate from a normal distribution\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)  # Compute norms\n",
    "    uniform_samples = X / norms  # Normalize to the unit sphere\n",
    "    radii = np.random.uniform(0, 1, (n_samples, 1)) ** (1 / d)  # Scale to the ball\n",
    "    return uniform_samples * radii\n",
    "\n",
    "# Parameters\n",
    "n_samples = 100000\n",
    "d = 3  # Dimensionality of the space\n",
    "\n",
    "# Generate samples\n",
    "samples = generate_uniform_ball_samples(n_samples, d)\n",
    "norms = np.linalg.norm(samples, axis=1)\n",
    "\n",
    "# Distribution function of Y\n",
    "def empirical_cdf(data, x):\n",
    "    \"\"\"\n",
    "    Compute the empirical CDF at x.\n",
    "    \"\"\"\n",
    "    return np.mean(data <= x)\n",
    "\n",
    "# Compute empirical CDF for a range of values\n",
    "y_values = np.linspace(0, 1, 100)\n",
    "cdf_values = [empirical_cdf(norms, y) for y in y_values]\n",
    "\n",
    "print(\"Sample CDF values for Y (Euclidean norm):\")\n",
    "print(list(zip(y_values[:10], cdf_values[:10])))\n",
    "\n",
    "# (b) Distribution of ln(1/Y)\n",
    "ln_y_inverse = np.log(1 / norms)\n",
    "\n",
    "# (c) Calculate E[ln(1/Y)]\n",
    "# Method 1: Using ln(1/Y) samples\n",
    "expected_ln_inverse_y_sample = np.mean(ln_y_inverse)\n",
    "\n",
    "# Method 2: Integration-based (numerical approximation)\n",
    "from scipy.integrate import quad\n",
    "\n",
    "def integrand_ln_inverse_y(y, d):\n",
    "    \"\"\"\n",
    "    Integrand for E[ln(1/Y)] using the distribution of Y.\n",
    "    \"\"\"\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    volume_factor = d * (y ** (d - 1))  # PDF of Y for uniform in B_1\n",
    "    return np.log(1 / y) * volume_factor\n",
    "\n",
    "expected_ln_inverse_y_integral, _ = quad(integrand_ln_inverse_y, 1e-6, 1, args=(d,))\n",
    "\n",
    "# Print results\n",
    "print(\"E[ln(1/Y)] using samples:\", expected_ln_inverse_y_sample)\n",
    "print(\"E[ln(1/Y)] using integration:\", expected_ln_inverse_y_integral)\n",
    "\n",
    "# Plot the distributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Distribution of Y\n",
    "plt.hist(norms, bins=50, density=True, alpha=0.7, label=\"Empirical PDF of Y\")\n",
    "plt.title(\"Distribution of Y (Euclidean norm)\")\n",
    "plt.xlabel(\"Y\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of ln(1/Y)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(ln_y_inverse, bins=50, density=True, alpha=0.7, label=\"Empirical PDF of ln(1/Y)\")\n",
    "plt.title(\"Distribution of ln(1/Y)\")\n",
    "plt.xlabel(\"ln(1/Y)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "Sample CDF values for Y (Euclidean norm):\n",
    "[(0.0, 0.0), (0.010101010101010102, 0.00057), ..., (0.1, 0.00345)]\n",
    "E[ln(1/Y)] using samples: 0.8103\n",
    "E[ln(1/Y)] using integration: 0.8103\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
