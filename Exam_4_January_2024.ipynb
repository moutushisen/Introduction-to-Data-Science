{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "261f7eab",
   "metadata": {},
   "source": [
    "# Exam 4th of January 2024\n",
    "**Course: 1MS041 (Introduction to Data Science)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f067f",
   "metadata": {},
   "source": [
    "\n",
    "This notebook contains the exam problems, instructions, and code cells required for completion.\n",
    "\n",
    "## Instructions\n",
    "1. Complete the problems by following the instructions.\n",
    "2. Submit the completed notebook with your solutions saved.\n",
    "3. This exam has **3 problems** for a total of **40 points**. To pass, you need **20 points**.\n",
    "4. Remember to comment your code to receive partial credit even if your solution is incorrect.\n",
    "5. Follow the instructions rigorously, and ensure that your answers are clear and unambiguous.\n",
    "6. You are **not allowed to communicate with others** or use external help (forums, AI tools, etc.).\n",
    "\n",
    "Good luck!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4762ed1d",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 1: Rejection Sampling and Monte Carlo Integration (14 Points)\n",
    "\n",
    "In this problem, you will perform rejection sampling from complex distributions and use your samples to compute integrals (Monte Carlo integration).\n",
    "\n",
    "### Tasks\n",
    "1. **[4 Points]** Complete the function `problem1_inversion` to produce samples from the given distribution using rejection sampling.\n",
    "2. **[2 Points]** Generate 100,000 samples using the above function, store them in `problem1_samples`, and plot the histogram with the true density.\n",
    "3. **[2 Points]** Use the generated samples to compute the integral:  \n",
    "   $$\\int_0^1 \\sin(x) \\frac{2e^{x^2}}{x} e^{-1} dx$$  \n",
    "   Store the result in `problem1_integral`.\n",
    "4. **[2 Points]** Use Hoeffding's inequality to compute a 95% confidence interval for the integral and store it in `problem1_interval`.\n",
    "5. **[4 Points]** Complete the function `problem1_inversion_2` to produce samples from a second distribution. Optimize the sampling distribution to minimize rejection.\n",
    "\n",
    "### Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ba910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Utils import timeout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Part 1: Fill in the function to perform rejection sampling\n",
    "@timeout\n",
    "def problem1_inversion(n_samples=1):\n",
    "    # Write your code here\n",
    "    return np.array([])\n",
    "\n",
    "# Part 2: Generate samples and plot histogram\n",
    "problem1_samples = None\n",
    "\n",
    "# Part 3: Compute integral using Monte Carlo\n",
    "problem1_integral = None\n",
    "\n",
    "# Part 4: Compute confidence interval using Hoeffding's inequality\n",
    "problem1_interval = None\n",
    "\n",
    "# Part 5: Complete a second inversion function\n",
    "def problem1_inversion_2(n_samples=1):\n",
    "    # Write your code here\n",
    "    return np.array([])\n",
    "\n",
    "# Local test for Problem 1\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion(10), np.ndarray))\n",
    "    print(\"Good: problem1_inversion returns a numpy array.\")\n",
    "except:\n",
    "    print(\"Error: problem1_inversion does not return a numpy array.\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_samples, np.ndarray))\n",
    "    print(\"Good: problem1_samples is a numpy array.\")\n",
    "except:\n",
    "    print(\"Error: problem1_samples is not a numpy array.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb8da3f",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 2: Logistic Regression for Spam Detection (13 Points)\n",
    "\n",
    "In this problem, you will build and calibrate a logistic regression model to classify emails as spam or not spam.\n",
    "\n",
    "### Tasks\n",
    "1. **[2 Points]** Load `data/spam.csv` and create numpy arrays `problem2_X` (shape `(n_emails, 3)`) and `problem2_Y` (shape `(n_emails,)`). Split the data into train (40%), calibration (20%), and test (40%) sets.\n",
    "2. **[4 Points]** Implement the loss function inside the `ProportionalSpam` class.\n",
    "3. **[4 Points]** Train the model on the training set. Calibrate probabilities using `DecisionTreeRegressor` and store the calibrated model.\n",
    "4. **[3 Points]** Use the trained and calibrated models to make predictions on the test set. Compute the 0-1 loss and provide a 99% confidence interval.\n",
    "\n",
    "### Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a28f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy import optimize\n",
    "\n",
    "# Part 1: Load data and split into train/calibration/test sets\n",
    "problem2_X = None\n",
    "problem2_Y = None\n",
    "problem2_X_train, problem2_X_calib, problem2_X_test = None, None, None\n",
    "problem2_Y_train, problem2_Y_calib, problem2_Y_test = None, None, None\n",
    "\n",
    "# Part 2: Define logistic regression model\n",
    "class ProportionalSpam:\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "\n",
    "    def loss(self, X, Y, coeffs):\n",
    "        # Define the loss function here\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        opt_loss = lambda coeffs: self.loss(X, Y, coeffs)\n",
    "        initial_args = np.zeros(X.shape[1] + 1)\n",
    "        self.result = optimize.minimize(opt_loss, initial_args, method=\"cg\")\n",
    "        self.coeffs = self.result.x\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.coeffs is not None:\n",
    "            G = lambda x: np.exp(x) / (1 + np.exp(x))\n",
    "            return np.round(10 * G(np.dot(X, self.coeffs[1:]) + self.coeffs[0])) / 10\n",
    "\n",
    "# Part 3: Train model and calibrate probabilities\n",
    "problem2_ps = None\n",
    "problem2_calibrator = None\n",
    "\n",
    "# Part 4: Make predictions and compute test loss\n",
    "problem2_final_predictions = None\n",
    "problem2_01_loss = None\n",
    "problem2_interval = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efabf3cf",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 3: Markov Chains (13 Points)\n",
    "\n",
    "Answer the following questions for four Markov chains.\n",
    "\n",
    "### Tasks\n",
    "1. **[2 Points]** Provide the transition matrix for each Markov chain.\n",
    "2. **[2 Points]** Determine if each chain is irreducible.\n",
    "3. **[3 Points]** Determine if each chain is aperiodic. Provide the period for each state.\n",
    "4. **[3 Points]** Determine if each chain has a stationary distribution. If it does, provide the distribution.\n",
    "5. **[3 Points]** Determine if each chain is reversible.\n",
    "\n",
    "### Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a666e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part 1: Transition matrices\n",
    "problem3_A = None\n",
    "problem3_B = None\n",
    "problem3_C = None\n",
    "problem3_D = None\n",
    "\n",
    "# Part 2: Irreducibility\n",
    "problem3_A_irreducible = None\n",
    "problem3_B_irreducible = None\n",
    "problem3_C_irreducible = None\n",
    "problem3_D_irreducible = None\n",
    "\n",
    "# Part 3: Aperiodicity and periods\n",
    "problem3_A_is_aperiodic = None\n",
    "problem3_B_is_aperiodic = None\n",
    "problem3_C_is_aperiodic = None\n",
    "problem3_D_is_aperiodic = None\n",
    "\n",
    "problem3_A_periods = None\n",
    "problem3_B_periods = None\n",
    "problem3_C_periods = None\n",
    "problem3_D_periods = None\n",
    "\n",
    "# Part 4: Stationary distributions\n",
    "problem3_A_has_stationary = None\n",
    "problem3_B_has_stationary = None\n",
    "problem3_C_has_stationary = None\n",
    "problem3_D_has_stationary = None\n",
    "\n",
    "problem3_A_stationary_dist = None\n",
    "problem3_B_stationary_dist = None\n",
    "problem3_C_stationary_dist = None\n",
    "problem3_D_stationary_dist = None\n",
    "\n",
    "# Part 5: Reversibility\n",
    "problem3_A_is_reversible = None\n",
    "problem3_B_is_reversible = None\n",
    "problem3_C_is_reversible = None\n",
    "problem3_D_is_reversible = None\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
