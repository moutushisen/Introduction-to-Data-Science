{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejection Sampling and Monte Carlo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def problem1_inversion(n_samples=1):\n",
    "    \"\"\"\n",
    "    Produces samples from the distribution:\n",
    "        F(x) = 0, x <= 0\n",
    "               (exp(x^2) - 1) / (exp(1) - 1), 0 < x < 1\n",
    "               1, x >= 1\n",
    "    \"\"\"\n",
    "    def target_pdf(x):\n",
    "        return (np.exp(x**2) - 1) / (np.exp(1) - 1)\n",
    "\n",
    "    # Sampling distribution: Uniform(0, 1)\n",
    "    def proposal_pdf(x):\n",
    "        return 1 if 0 <= x <= 1 else 0\n",
    "\n",
    "    c = (np.exp(1) - 1)  # Maximum of target_pdf within range\n",
    "\n",
    "    samples = []\n",
    "    while len(samples) < n_samples:\n",
    "        x = np.random.uniform(0, 1)\n",
    "        u = np.random.uniform(0, c * proposal_pdf(x))\n",
    "        if u <= target_pdf(x):\n",
    "            samples.append(x)\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "# Part 2: Generate 100,000 samples\n",
    "problem1_samples = problem1_inversion(n_samples=100000)\n",
    "\n",
    "# Plot histogram with true density\n",
    "x_vals = np.linspace(0, 1, 500)\n",
    "true_density = (np.exp(x_vals**2) - 1) / (np.exp(1) - 1)\n",
    "plt.hist(problem1_samples, bins=50, density=True, alpha=0.6, label=\"Samples\")\n",
    "plt.plot(x_vals, true_density, label=\"True Density\", linewidth=2)\n",
    "plt.legend()\n",
    "plt.title(\"Histogram and True Density\")\n",
    "plt.show()\n",
    "\n",
    "# Part 3: Monte Carlo Integration\n",
    "integrand = lambda x: np.sin(x) * (2 * np.exp(x**2)) / ((np.exp(1) - 1) * x)\n",
    "values = integrand(problem1_samples)\n",
    "problem1_integral = np.mean(values)\n",
    "\n",
    "# Part 4: Hoeffding's Inequality for Confidence Interval\n",
    "confidence_level = 0.95\n",
    "epsilon = np.sqrt(np.log(2 / (1 - confidence_level)) / (2 * len(values)))\n",
    "problem1_interval = [problem1_integral - epsilon, problem1_integral + epsilon]\n",
    "\n",
    "# Part 5: Second Distribution\n",
    "\n",
    "def problem1_inversion_2(n_samples=1):\n",
    "    \"\"\"\n",
    "    Produces samples from the distribution:\n",
    "        F(x) = 0, x <= 0\n",
    "               20x * exp(20 - 1/x), 0 < x < 1\n",
    "               20, x >= 1\n",
    "    \"\"\"\n",
    "    def target_pdf(x):\n",
    "        return 20 * x * np.exp(20 - 1 / x) if 0 < x <= 1 else 0\n",
    "\n",
    "    # Sampling distribution: Exponential(1/20)\n",
    "    def proposal_sampler():\n",
    "        return np.random.exponential(1 / 20)\n",
    "\n",
    "    def proposal_pdf(x):\n",
    "        return 20 * np.exp(-20 * x) if x > 0 else 0\n",
    "\n",
    "    c = 20 * np.exp(20 - 1)  # Maximum of target_pdf / proposal_pdf\n",
    "\n",
    "    samples = []\n",
    "    while len(samples) < n_samples:\n",
    "        x = proposal_sampler()\n",
    "        if 0 < x <= 1:  # Ensure x is within the domain\n",
    "            u = np.random.uniform(0, c * proposal_pdf(x))\n",
    "            if u <= target_pdf(x):\n",
    "                samples.append(x)\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "# Verify outputs\n",
    "print(\"Generated values:\")\n",
    "print(\"Integral Estimate:\", problem1_integral)\n",
    "print(\"Confidence Interval:\", problem1_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Spam Model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Part 1: Loading the data and splitting into train, calibration, and test sets\n",
    "# Replace 'data/spam.csv' with the actual path to your CSV file\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data/spam.csv')\n",
    "\n",
    "# Extract features and labels\n",
    "problem2_X = data[['free', 'prize', 'win']].values  # Assuming these columns correspond to X1, X2, X3\n",
    "problem2_Y = data['spam'].values  # Assuming 'spam' column corresponds to Y\n",
    "\n",
    "# Split into train, calibration, and test sets\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(problem2_X, problem2_Y, test_size=0.6, random_state=42)\n",
    "X_calib, X_test, Y_calib, Y_test = train_test_split(X_temp, Y_temp, test_size=2/3, random_state=42)\n",
    "\n",
    "problem2_X_train, problem2_X_calib, problem2_X_test = X_train, X_calib, X_test\n",
    "problem2_Y_train, problem2_Y_calib, problem2_Y_test = Y_train, Y_calib, Y_test\n",
    "\n",
    "print(problem2_X_train.shape, problem2_X_calib.shape, problem2_X_test.shape, problem2_Y_train.shape, problem2_Y_calib.shape, problem2_Y_test.shape)\n",
    "\n",
    "# Part 2: Implementing ProportionalSpam class\n",
    "class ProportionalSpam:\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "\n",
    "    def loss(self, X, Y, coeffs):\n",
    "        G = lambda x: np.exp(x) / (1 + np.exp(x))\n",
    "        logits = np.dot(X, coeffs[1:]) + coeffs[0]\n",
    "        probabilities = G(logits)\n",
    "        loss = -np.mean(Y * np.log(probabilities + 1e-9) + (1 - Y) * np.log(1 - probabilities + 1e-9))\n",
    "        return loss\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        X_with_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        initial_arguments = np.zeros(X_with_bias.shape[1])\n",
    "        opt_loss = lambda coeffs: self.loss(X, Y, coeffs)\n",
    "        self.result = minimize(opt_loss, initial_arguments, method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.coeffs is not None:\n",
    "            G = lambda x: np.exp(x) / (1 + np.exp(x))\n",
    "            logits = np.dot(X, self.coeffs[1:]) + self.coeffs[0]\n",
    "            probabilities = G(logits)\n",
    "            return probabilities\n",
    "        return None\n",
    "\n",
    "# Part 3: Training the model and calibrator\n",
    "problem2_ps = ProportionalSpam()\n",
    "problem2_ps.fit(problem2_X_train, problem2_Y_train)\n",
    "\n",
    "# Predict on the calibration dataset\n",
    "problem2_X_pred = problem2_ps.predict(problem2_X_calib).reshape(-1, 1)\n",
    "\n",
    "# Train the calibrator\n",
    "problem2_calibrator = DecisionTreeRegressor()\n",
    "problem2_calibrator.fit(problem2_X_pred, problem2_Y_calib)\n",
    "\n",
    "# Part 4: Making final predictions and calculating 0-1 loss and confidence interval\n",
    "# Predict on the test dataset\n",
    "predicted_probabilities = problem2_ps.predict(problem2_X_test).reshape(-1, 1)\n",
    "calibrated_probabilities = problem2_calibrator.predict(predicted_probabilities)\n",
    "\n",
    "# Convert probabilities to binary predictions (Bayes classifier)\n",
    "problem2_final_predictions = (calibrated_probabilities >= 0.5).astype(int)\n",
    "\n",
    "# Compute 0-1 loss\n",
    "problem2_01_loss = np.mean(problem2_final_predictions != problem2_Y_test)\n",
    "\n",
    "# Compute 99% confidence interval for the 0-1 loss\n",
    "n_test = len(problem2_Y_test)\n",
    "loss_variance = (problem2_01_loss * (1 - problem2_01_loss)) / n_test\n",
    "z_score = norm.ppf(0.995)  # 99% confidence interval\n",
    "margin_of_error = z_score * np.sqrt(loss_variance)\n",
    "problem2_interval = (problem2_01_loss - margin_of_error, problem2_01_loss + margin_of_error)\n",
    "\n",
    "# Output results\n",
    "print(\"0-1 Loss:\", problem2_01_loss)\n",
    "print(\"99% Confidence Interval:\", problem2_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov Chain Analysis\n",
    "import numpy as np\n",
    "\n",
    "# PART 1: TRANSITION MATRIX\n",
    "# Transition matrices for Markov Chains A, B, C, and D\n",
    "problem3_A = np.array([\n",
    "    [0.8, 0.2, 0.0, 0.0],  # A -> A, B, C, D\n",
    "    [0.6, 0.2, 0.2, 0.0],  # B -> A, B, C, D\n",
    "    [0.0, 0.4, 0.6, 0.0],  # C -> A, B, C, D\n",
    "    [0.0, 0.0, 0.2, 0.8],  # D -> A, B, C, D\n",
    "])\n",
    "\n",
    "problem3_B = np.array([\n",
    "    [0.8, 0.0, 0.0, 0.2],\n",
    "    [0.2, 0.0, 1.0, 0.0],\n",
    "    [0.0, 1.0, 0.0, 0.0],\n",
    "    [0.0, 0.5, 0.5, 0.0],\n",
    "])\n",
    "\n",
    "problem3_C = np.array([\n",
    "    [0.2, 0.3, 0.2, 0.0, 0.5],\n",
    "    [0.3, 0.2, 0.0, 0.4, 0.1],\n",
    "    [0.0, 0.6, 0.0, 0.0, 0.4],\n",
    "    [0.4, 0.0, 0.6, 0.0, 0.0],\n",
    "    [0.6, 0.0, 0.0, 0.4, 0.0],\n",
    "])\n",
    "\n",
    "problem3_D = np.array([\n",
    "    [0.8, 0.2, 0.0, 0.0],\n",
    "    [0.6, 0.2, 0.2, 0.0],\n",
    "    [0.0, 0.4, 0.6, 0.0],\n",
    "    [0.1, 0.0, 0.7, 0.2],\n",
    "])\n",
    "\n",
    "# PART 2: IRREDUCIBLE\n",
    "# Irreducibility checks for each Markov chain\n",
    "problem3_A_irreducible = True\n",
    "problem3_B_irreducible = False  # B and D are disconnected\n",
    "problem3_C_irreducible = True\n",
    "problem3_D_irreducible = True\n",
    "\n",
    "# PART 3: APERIODICITY\n",
    "# Aperiodicity checks and periods\n",
    "problem3_A_is_aperiodic = True\n",
    "problem3_B_is_aperiodic = False  # B has a period of 2\n",
    "problem3_C_is_aperiodic = True\n",
    "problem3_D_is_aperiodic = True\n",
    "\n",
    "problem3_A_periods = np.array([1, 1, 1, 1])\n",
    "problem3_B_periods = np.array([1, 2, 2, 1])\n",
    "problem3_C_periods = np.array([1, 1, 1, 1, 1])\n",
    "problem3_D_periods = np.array([1, 1, 1, 1])\n",
    "\n",
    "# PART 4: STATIONARY DISTRIBUTION\n",
    "# Stationary distributions\n",
    "problem3_A_has_stationary = True\n",
    "problem3_B_has_stationary = True\n",
    "problem3_C_has_stationary = True\n",
    "problem3_D_has_stationary = True\n",
    "\n",
    "# Calculate stationary distributions\n",
    "def stationary_distribution(P):\n",
    "    eigvals, eigvecs = np.linalg.eig(P.T)\n",
    "    stationary = eigvecs[:, np.isclose(eigvals, 1)]\n",
    "    stationary = stationary / stationary.sum()\n",
    "    return stationary.real.ravel()\n",
    "\n",
    "problem3_A_stationary_dist = stationary_distribution(problem3_A)\n",
    "problem3_B_stationary_dist = stationary_distribution(problem3_B)\n",
    "problem3_C_stationary_dist = stationary_distribution(problem3_C)\n",
    "problem3_D_stationary_dist = stationary_distribution(problem3_D)\n",
    "\n",
    "# PART 5: REVERSIBILITY\n",
    "# Reversibility checks (Detailed balance condition)\n",
    "def is_reversible(P, pi):\n",
    "    n = len(pi)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if not np.isclose(pi[i] * P[i, j], pi[j] * P[j, i]):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "problem3_A_is_reversible = is_reversible(problem3_A, problem3_A_stationary_dist)\n",
    "problem3_B_is_reversible = is_reversible(problem3_B, problem3_B_stationary_dist)\n",
    "problem3_C_is_reversible = is_reversible(problem3_C, problem3_C_stationary_dist)\n",
    "problem3_D_is_reversible = is_reversible(problem3_D, problem3_D_stationary_dist)\n",
    "\n",
    "# Print Results\n",
    "results = {\n",
    "    \"Transition Matrices\": [problem3_A, problem3_B, problem3_C, problem3_D],\n",
    "    \"Irreducibility\": [problem3_A_irreducible, problem3_B_irreducible, problem3_C_irreducible, problem3_D_irreducible],\n",
    "    \"Aperiodicity\": [problem3_A_is_aperiodic, problem3_B_is_aperiodic, problem3_C_is_aperiodic, problem3_D_is_aperiodic],\n",
    "    \"Periods\": [problem3_A_periods, problem3_B_periods, problem3_C_periods, problem3_D_periods],\n",
    "    \"Stationary Distributions\": [\n",
    "        problem3_A_stationary_dist,\n",
    "        problem3_B_stationary_dist,\n",
    "        problem3_C_stationary_dist,\n",
    "        problem3_D_stationary_dist,\n",
    "    ],\n",
    "    \"Reversibility\": [\n",
    "        problem3_A_is_reversible,\n",
    "        problem3_B_is_reversible,\n",
    "        problem3_C_is_reversible,\n",
    "        problem3_D_is_reversible,\n",
    "    ],\n",
    "}\n",
    "\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
