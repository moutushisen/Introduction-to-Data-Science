{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exam 14th of January 2020 Solutions for 1MS041\n",
    "\n",
    "# Problem 1: Singular Value Decomposition (SVD)\n",
    "from sympy import Matrix, sqrt\n",
    "\n",
    "M = Matrix([[1, 1], [0, 3], [3, 0]])\n",
    "rank = M.rank()\n",
    "\n",
    "# Compute SVD manually (eigenvalue decomposition for symmetric M.T * M and M * M.T)\n",
    "eigenvalues_v = M.T * M\n",
    "eigenvalues_u = M * M.T\n",
    "\n",
    "# Singular values\n",
    "singular_values = [sqrt(val) for val in eigenvalues_v.eigenvals().keys()]\n",
    "D = Matrix.diag(*singular_values)\n",
    "\n",
    "# Eigenvectors (normalized for U and V)\n",
    "U = eigenvalues_u.eigenvects()[0][2][0].normalized()\n",
    "V = eigenvalues_v.eigenvects()[0][2][0].normalized()\n",
    "\n",
    "print(f\"Rank: {rank}\")\n",
    "print(f\"U: {U}\")\n",
    "print(f\"D: {D}\")\n",
    "print(f\"V: {V}\")\n",
    "\n",
    "# Problem 2: Wald Test\n",
    "import numpy as np\n",
    "\n",
    "dataSamples2 = np.array([-10, 10, 10, -10, -10, -10, 10, 10, -10, -10, -10, 10, 10, -10, 10, 10, 10])\n",
    "\n",
    "# Compute MLE for theta\n",
    "count_10 = sum(dataSamples2 == 10)\n",
    "count_neg10 = sum(dataSamples2 == -10)\n",
    "thetaHat = count_10 / len(dataSamples2)\n",
    "\n",
    "# Null hypothesis value\n",
    "NullTheta = 0.5\n",
    "\n",
    "# Standard error (sqrt[Fisher Information])\n",
    "n = len(dataSamples2)\n",
    "seTheta = np.sqrt((NullTheta * (1 - NullTheta)) / n)\n",
    "\n",
    "# Wald Statistic\n",
    "W = (thetaHat - NullTheta) / seTheta\n",
    "rejectNull1 = abs(W) > 2.0\n",
    "print(\"MLE thetaHat =\", thetaHat)\n",
    "print(\"Wald statistic =\", W)\n",
    "if rejectNull1:\n",
    "    print(\"Reject the null hypothesis that theta_0=0.5\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis that theta_0=0.5\")\n",
    "\n",
    "# Problem 3: Residual Analysis\n",
    "from scipy.linalg import lstsq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Mock example data\n",
    "eqDepth = np.linspace(1, 10, 20)\n",
    "eqMagnitude = 2.5 + 0.75 * eqDepth + np.random.normal(0, 0.5, size=len(eqDepth))\n",
    "\n",
    "# Fit least squares model\n",
    "M1 = np.vstack([np.ones_like(eqDepth), eqDepth]).T\n",
    "b, *_ = lstsq(M1, eqMagnitude)\n",
    "\n",
    "# Residual plot\n",
    "residuals = eqMagnitude - (b[0] + b[1] * eqDepth)\n",
    "plt.scatter(eqDepth, residuals)\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n",
    "\n",
    "# Wald Test for beta_1=0\n",
    "se_beta1 = np.sqrt(np.var(residuals) / (eqDepth - eqDepth.mean())**2).sum()\n",
    "W_beta1 = b[1] / se_beta1\n",
    "RejectNullHypothesisForProblem4 = abs(W_beta1) > 1.96\n",
    "print(\"Reject Null Hypothesis for beta_1=0:\", RejectNullHypothesisForProblem4)\n",
    "\n",
    "# Problem 4: Transition Matrix for Markov Chain\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Parse text\n",
    "text = '''It is a truth universally acknowledged...'''.lower()\n",
    "words = re.findall(r\"\\w+\", text)\n",
    "unique_words = sorted(set(words))\n",
    "wordToIndex = {word: idx for idx, word in enumerate(unique_words)}\n",
    "\n",
    "# Count transitions\n",
    "transitions = [(words[i], words[i + 1]) for i in range(len(words) - 1)]\n",
    "transition_counts = Counter(transitions)\n",
    "\n",
    "# Transition matrix\n",
    "n_words = len(unique_words)\n",
    "transition_matrix = np.zeros((n_words, n_words))\n",
    "for (w1, w2), count in transition_counts.items():\n",
    "    i, j = wordToIndex[w1], wordToIndex[w2]\n",
    "    transition_matrix[i, j] = count\n",
    "\n",
    "# Normalize rows\n",
    "transition_matrix /= transition_matrix.sum(axis=1, keepdims=True)\n",
    "print(\"Transition matrix computed.\")\n",
    "\n",
    "# Problem 5: Sphere Statistics\n",
    "from sympy import symbols, gamma, pi\n",
    "\n",
    "# Variance of X1\n",
    "d = symbols('d')\n",
    "variance_x1_problem7 = 1 / d\n",
    "\n",
    "# Epsilon for 99% shell volume\n",
    "epsilon = symbols('epsilon')\n",
    "volume_shell = 1 - (1 - epsilon**d)\n",
    "\n",
    "# Radius for constant volume\n",
    "r = (gamma(d / 2 + 1) / (pi**(d / 2)))**(1 / d)\n",
    "print(f\"Variance: {variance_x1_problem7}, Radius: {r}\")\n",
    "\n",
    "# Problem 6: Perceptron Algorithm\n",
    "\n",
    "def perceptron(X, y, max_iter=1000):\n",
    "    w = np.zeros(X.shape[1] + 1)\n",
    "    for _ in range(max_iter):\n",
    "        for i, x in enumerate(X):\n",
    "            x_ext = np.insert(x, 0, 1)\n",
    "            if y[i] * np.dot(w, x_ext) <= 0:\n",
    "                w += y[i] * x_ext\n",
    "    return w\n",
    "\n",
    "hat_w = perceptron(X, y)\n",
    "print(\"Weight vector:\", hat_w)\n",
    "\n",
    "# Problem 7: Bootstrap Confidence Interval\n",
    "from random import randint\n",
    "\n",
    "def bootstrap(data, func, B=1000, alpha=0.05):\n",
    "    estimates = [func(np.random.choice(data, len(data), replace=True)) for _ in range(B)]\n",
    "    lower = np.percentile(estimates, 100 * alpha / 2)\n",
    "    upper = np.percentile(estimates, 100 * (1 - alpha / 2))\n",
    "    return lower, upper\n",
    "\n",
    "data = np.random.exponential(scale=10, size=100)\n",
    "func = lambda x: np.percentile(x, 95)\n",
    "ci = bootstrap(data, func)\n",
    "print(\"95th Percentile CI:\", ci)\n",
    "\n",
    "# Problem 8: Optimization for MLE\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "def neg_log_likelihood(beta):\n",
    "    return -np.sum(np.log((dataSamples1 / beta**2) * np.exp(-0.5 * (dataSamples1 / beta)**2)))\n",
    "\n",
    "result = minimize_scalar(neg_log_likelihood, bounds=(0.1, 10), method=\"bounded\")\n",
    "print(\"MLE for beta:\", result.x)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
