{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov Chain Analysis\n",
    "import numpy as np\n",
    "\n",
    "# Transition matrix\n",
    "transition_matrix = np.array([\n",
    "    [0.3, 0.4, 0.3],  # Downtown\n",
    "    [0.2, 0.5, 0.3],  # Suburbs\n",
    "    [0.4, 0.3, 0.3]   # Countryside\n",
    "])\n",
    "\n",
    "# Part 1: Probability of being in downtown after two steps from suburbs\n",
    "initial_state_suburbs = np.array([0, 1, 0])  # Start in suburbs\n",
    "prob_two_steps = np.dot(initial_state_suburbs, np.linalg.matrix_power(transition_matrix, 2))\n",
    "problem1_p1 = prob_two_steps[0]\n",
    "\n",
    "# Part 2: Probability of first being in downtown after two steps from suburbs\n",
    "# We calculate the probability of going from suburbs to suburbs in the first step,\n",
    "# and then from suburbs to downtown in the second step.\n",
    "prob_first_downtown_two_steps = (\n",
    "    transition_matrix[1, 1] * transition_matrix[1, 0]\n",
    ")\n",
    "problem1_p2 = prob_first_downtown_two_steps\n",
    "\n",
    "# Part 3: Is the Markov chain irreducible?\n",
    "# The Markov chain is irreducible if it's possible to go from any state to any other state.\n",
    "def is_irreducible(matrix):\n",
    "    n = matrix.shape[0]\n",
    "    reachable = np.linalg.matrix_power(matrix, n - 1) > 0\n",
    "    return np.all(reachable)\n",
    "\n",
    "problem1_irreducible = is_irreducible(transition_matrix)\n",
    "\n",
    "# Part 4: Stationary distribution\n",
    "# Solve for the stationary distribution \\pi such that \\pi * P = \\pi\n",
    "# and the entries of \\pi sum to 1.\n",
    "def stationary_distribution(matrix):\n",
    "    n = matrix.shape[0]\n",
    "    A = np.vstack((matrix.T - np.eye(n), np.ones(n)))\n",
    "    b = np.append(np.zeros(n), 1)\n",
    "    return np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "\n",
    "problem1_stationary = stationary_distribution(transition_matrix)\n",
    "\n",
    "# Part 5: Expected number of steps to enter the suburbs starting from downtown\n",
    "# Use hitting time calculations.\n",
    "max_steps = 30\n",
    "hitting_probabilities = []\n",
    "for step in range(1, max_steps + 1):\n",
    "    hitting_matrix = np.linalg.matrix_power(transition_matrix, step)\n",
    "    hitting_probabilities.append(hitting_matrix[0, 1])\n",
    "\n",
    "expected_hitting_time = sum(step * hitting_probabilities[step - 1] for step in range(1, max_steps + 1))\n",
    "problem1_ET = expected_hitting_time\n",
    "\n",
    "# Print results\n",
    "print(f\"Part 1: Probability of being in downtown after two steps = {problem1_p1}\")\n",
    "print(f\"Part 2: Probability of first being in downtown after two steps = {problem1_p2}\")\n",
    "print(f\"Part 3: Is the Markov chain irreducible? {problem1_irreducible}\")\n",
    "print(f\"Part 4: Stationary distribution = {problem1_stationary}\")\n",
    "print(f\"Part 5: Expected number of steps to enter the suburbs = {problem1_ET}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abalone Regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Part 1: Load the dataset into a DataFrame\n",
    "file_path = 'data/abalone.csv'\n",
    "problem2_df = pd.read_csv(file_path)\n",
    "\n",
    "# Extract features and target based on column names\n",
    "problem2_features = ['Length', 'Diameter', 'Height', 'WholeWeight', 'ShuckedWeight', 'VisceraWeight', 'ShellWeight']\n",
    "problem2_target = 'Rings'\n",
    "\n",
    "# Part 2: Split the dataset into training and testing sets\n",
    "X = problem2_df[problem2_features]\n",
    "y = problem2_df[problem2_target]\n",
    "problem2_X_train, problem2_X_test, problem2_y_train, problem2_y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Part 3: Train a linear regression model\n",
    "problem2_model = LinearRegression()\n",
    "problem2_model.fit(problem2_X_train, problem2_y_train)\n",
    "\n",
    "# Part 4: Evaluate the model with MAE and plot EDF of residuals\n",
    "# Compute predictions\n",
    "problem2_y_pred = problem2_model.predict(problem2_X_test)\n",
    "\n",
    "# Compute Mean Absolute Error (MAE)\n",
    "problem2_mae = mean_absolute_error(problem2_y_test, problem2_y_pred)\n",
    "\n",
    "# Plot Empirical Distribution Function (EDF) of residuals\n",
    "residuals = problem2_y_test - problem2_y_pred\n",
    "\n",
    "# Function to compute EDF and confidence bands using the DKW inequality\n",
    "def makeEDF(data):\n",
    "    sorted_data = np.sort(data)\n",
    "    n = len(data)\n",
    "    y = np.arange(1, n + 1) / n\n",
    "    epsilon = np.sqrt(np.log(2 / 0.05) / (2 * n))\n",
    "    return sorted_data, y, epsilon\n",
    "\n",
    "def plotEDF(data):\n",
    "    x, y, epsilon = makeEDF(data)\n",
    "    plt.step(x, y, label='EDF')\n",
    "    plt.fill_between(x, np.maximum(0, y - epsilon), np.minimum(1, y + epsilon), color='blue', alpha=0.2, label='95% Confidence Band')\n",
    "    plt.xlabel('Residuals')\n",
    "    plt.ylabel('EDF')\n",
    "    plt.title('Empirical Distribution Function of Residuals')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotEDF(residuals)\n",
    "\n",
    "# Part 5: Scatter plot of predicted vs. true values\n",
    "plt.scatter(problem2_y_pred, problem2_y_test, alpha=0.6)\n",
    "plt.plot([min(problem2_y_test), max(problem2_y_test)], [min(problem2_y_test), max(problem2_y_test)], color='red', linestyle='--', label='Ideal Fit')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('True Values')\n",
    "plt.title('Predicted vs True Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Part 6: Discussion\n",
    "print(\"Discussion:\\n\")\n",
    "print(f\"1. The Mean Absolute Error (MAE) is {problem2_mae:.2f}. This provides an indication of the average deviation of predictions from the true values.\")\n",
    "print(\"2. The scatter plot shows how well the predictions align with the true values. Ideally, the points should cluster around the diagonal red line. Deviations from this line indicate prediction errors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson Regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Part 1: Load the data and decide features and target\n",
    "# Load the data\n",
    "data_path = 'data/visits_clean.csv'  # Update the file path as necessary\n",
    "problem3_df = pd.read_csv(data_path)\n",
    "\n",
    "# Selecting features and target based on the problem statement\n",
    "# Features exclude \"ofnp\", \"opp\", \"opnp\", \"emr\", \"hosp\" as they may correlate directly\n",
    "# Target: \"ofp\" (number of physician office visits)\n",
    "problem3_features = [\n",
    "    \"exclhlth\", \"poorhealth\", \"numchron\", \"adldiff\", \"noreast\", \"midwest\",\n",
    "    \"west\", \"age\", \"male\", \"married\", \"school\", \"faminc\", \"employed\",\n",
    "    \"privins\", \"medicaid\"\n",
    "]\n",
    "problem3_target = \"ofp\"\n",
    "\n",
    "# Part 2: Create X and y and perform train-test split\n",
    "problem3_X = problem3_df[problem3_features].to_numpy()\n",
    "problem3_y = problem3_df[problem3_target].to_numpy()\n",
    "\n",
    "# Train-test split\n",
    "problem3_X_train, problem3_X_test, problem3_y_train, problem3_y_test = train_test_split(\n",
    "    problem3_X, problem3_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Part 3: Implement the loss function\n",
    "class PoissonRegression:\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        def loss(coeffs):\n",
    "            lam = np.exp(np.dot(X, coeffs[:-1]) + coeffs[-1])\n",
    "            return -np.sum(Y * np.log(lam) - lam)\n",
    "\n",
    "        initial_arguments = np.zeros(shape=X.shape[1] + 1)  # Initial guess as 0\n",
    "        self.result = optimize.minimize(loss, initial_arguments, method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.coeffs is not None:\n",
    "            return np.exp(np.dot(X, self.coeffs[:-1]) + self.coeffs[-1])\n",
    "        return None\n",
    "\n",
    "# Part 4: Train the model\n",
    "problem3_model = PoissonRegression()\n",
    "problem3_model.fit(problem3_X_train, problem3_y_train)\n",
    "\n",
    "# Check if optimization was successful\n",
    "print(\"Optimization success:\", problem3_model.result.success)\n",
    "\n",
    "# Part 5: Evaluate the model\n",
    "# Using Mean Absolute Error (MAE) as the metric\n",
    "problem3_y_pred = problem3_model.predict(problem3_X_test)\n",
    "problem3_metric = mean_absolute_error(problem3_y_test, problem3_y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", problem3_metric)\n",
    "\n",
    "# Discussion on naive model comparison\n",
    "naive_prediction = np.mean(problem3_y_train)  # Using the mean of the training set as a naive prediction\n",
    "naive_mae = mean_absolute_error(problem3_y_test, np.full_like(problem3_y_test, naive_prediction))\n",
    "print(\"Naive Mean Absolute Error (MAE):\", naive_mae)\n",
    "\n",
    "# Interpretation\n",
    "if problem3_metric < naive_mae:\n",
    "    print(\"The Poisson regression model performs better than the naive model.\")\n",
    "else:\n",
    "    print(\"The Poisson regression model does not outperform the naive model.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
