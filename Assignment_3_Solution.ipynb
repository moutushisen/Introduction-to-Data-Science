{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 1\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the data\n",
    "wind_direction = []\n",
    "wind_speed = []\n",
    "\n",
    "with open(r\"D:\\Data Science LAB\\data\\smhi.csv\", 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=';')  # Adjust delimiter if necessary\n",
    "    for row in reader:\n",
    "        direction = row['Vindriktning']  # Wind Direction in Swedish\n",
    "        speed = row['Vindhastighet']     # Wind Speed in Swedish\n",
    "        # Handle missing or invalid data\n",
    "        if direction != '' and speed != '':\n",
    "            try:\n",
    "                wind_direction.append(float(direction))\n",
    "                wind_speed.append(float(speed))\n",
    "            except ValueError:\n",
    "                continue  # Skip rows with invalid data\n",
    "\n",
    "problem1_wind_direction = np.array(wind_direction)\n",
    "problem1_wind_speed = np.array(wind_speed)\n",
    "\n",
    "# 2. Convert wind direction to x and y coordinates\n",
    "# Convert compass degrees to mathematical degrees\n",
    "math_angle = (90 - problem1_wind_direction) % 360\n",
    "theta = np.deg2rad(math_angle)\n",
    "\n",
    "# x and y coordinates on the unit circle\n",
    "problem1_wind_direction_x_coordinate = np.cos(theta)\n",
    "problem1_wind_direction_y_coordinate = np.sin(theta)\n",
    "\n",
    "# Wind velocity components\n",
    "problem1_wind_velocity_x_coordinate = problem1_wind_speed * problem1_wind_direction_x_coordinate\n",
    "problem1_wind_velocity_y_coordinate = problem1_wind_speed * problem1_wind_direction_y_coordinate\n",
    "\n",
    "# 3. Calculate the average wind velocity and compare angles\n",
    "problem1_average_wind_velocity_x_coordinate = np.mean(problem1_wind_velocity_x_coordinate)\n",
    "problem1_average_wind_velocity_y_coordinate = np.mean(problem1_wind_velocity_y_coordinate)\n",
    "\n",
    "# Angle of the average wind velocity vector\n",
    "avg_velocity_angle_rad = np.arctan2(problem1_average_wind_velocity_y_coordinate,\n",
    "                                    problem1_average_wind_velocity_x_coordinate)\n",
    "problem1_average_wind_velocity_angle_degrees = (np.rad2deg(avg_velocity_angle_rad)) % 360\n",
    "\n",
    "# Average of the wind direction as given in the data\n",
    "problem1_average_wind_direction_angle_degrees = np.mean(problem1_wind_direction)\n",
    "\n",
    "# Compare the angles\n",
    "problem1_same_angle = np.isclose(problem1_average_wind_velocity_angle_degrees,\n",
    "                                 problem1_average_wind_direction_angle_degrees)\n",
    "\n",
    "# 4. Calculate the empirical covariance matrix\n",
    "wind_velocity = np.vstack((problem1_wind_velocity_x_coordinate,\n",
    "                           problem1_wind_velocity_y_coordinate))\n",
    "problem1_wind_velocity_covariance_matrix = np.cov(wind_velocity)\n",
    "\n",
    "# Output variables\n",
    "print(\"problem1_wind_direction =\", problem1_wind_direction)\n",
    "print(\"problem1_wind_speed =\", problem1_wind_speed)\n",
    "print(\"problem1_wind_direction_x_coordinate =\", problem1_wind_direction_x_coordinate)\n",
    "print(\"problem1_wind_direction_y_coordinate =\", problem1_wind_direction_y_coordinate)\n",
    "print(\"problem1_wind_velocity_x_coordinate =\", problem1_wind_velocity_x_coordinate)\n",
    "print(\"problem1_wind_velocity_y_coordinate =\", problem1_wind_velocity_y_coordinate)\n",
    "print(\"problem1_average_wind_velocity_x_coordinate =\", problem1_average_wind_velocity_x_coordinate)\n",
    "print(\"problem1_average_wind_velocity_y_coordinate =\", problem1_average_wind_velocity_y_coordinate)\n",
    "print(\"problem1_average_wind_velocity_angle_degrees =\", problem1_average_wind_velocity_angle_degrees)\n",
    "print(\"problem1_average_wind_direction_angle_degrees =\", problem1_average_wind_direction_angle_degrees)\n",
    "print(\"problem1_same_angle =\", problem1_same_angle)\n",
    "print(\"problem1_wind_velocity_covariance_matrix =\", problem1_wind_velocity_covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the full arrays for wind direction and wind speed\n",
    "problem1_wind_direction = wind_direction  # Wind direction in degrees\n",
    "problem1_wind_speed = wind_speed  # Wind speed in m/s\n",
    "\n",
    "problem1_wind_direction, problem1_wind_speed\n",
    "\n",
    "Result\n",
    "(array([348,  43, 185, ..., 269, 281, 252]),\n",
    " array([0.6, 0.2, 0.1, ..., 1.6, 1.4, 1.4]))\n",
    "Result\n",
    "{'problem1_wind_direction_x_coordinate': array([ 0.9781476 ,  0.7313537 , -0.9961947 , -0.58778525, -0.64278761]),\n",
    " 'problem1_wind_direction_y_coordinate': array([-0.20791169,  0.68199836, -0.08715574,  0.80901699,  0.76604444]),\n",
    " 'problem1_wind_velocity_x_coordinate': array([ 0.58688856,  0.14627074, -0.09961947, -0.4702282 , -0.44995133]),\n",
    " 'problem1_wind_velocity_y_coordinate': array([-0.12474701,  0.13639967, -0.00871557,  0.6472136 ,  0.53623111]),\n",
    " 'problem1_average_wind_velocity_x_coordinate': -1.038909498722117,\n",
    " 'problem1_average_wind_velocity_y_coordinate': -0.3807312196610262,\n",
    " 'problem1_average_wind_velocity_angle_degrees': 200.12646997879915,\n",
    " 'problem1_average_wind_direction_angle_degrees': 192.281280627246,\n",
    " 'problem1_same_angle': False,\n",
    " 'problem1_wind_velocity_covariance_matrix': array([[2.45331787, 0.06366291],[0.06366291, 1.89213988]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 1 - 2 solution\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# 1. Load the data\n",
    "wind_directions = []\n",
    "wind_speeds = []\n",
    "\n",
    "with open(r\"D:\\Data Science LAB\\data\\smhi.csv\", 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=';')\n",
    "    next(reader)  # Skip header\n",
    "    for row in reader:\n",
    "        # The wind speed is in the 5th column (index 4)\n",
    "        # The wind direction is in the 8th column (index 7)\n",
    "        wind_speed = row[4]\n",
    "        wind_direction = row[7]\n",
    "        # Convert to float and handle missing data\n",
    "        try:\n",
    "            wind_speeds.append(float(wind_speed))\n",
    "            wind_directions.append(float(wind_direction))\n",
    "        except ValueError:\n",
    "            pass  # Skip rows with invalid data\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "problem1_wind_direction = np.array(wind_directions)\n",
    "problem1_wind_speed = np.array(wind_speeds)\n",
    "\n",
    "# 2. Convert wind direction to x and y coordinates on the unit circle\n",
    "theta = np.radians(90 - problem1_wind_direction)  # Convert compass degrees to radians\n",
    "problem1_wind_direction_x_coordinate = np.cos(theta)\n",
    "problem1_wind_direction_y_coordinate = np.sin(theta)\n",
    "\n",
    "# Construct wind velocity vectors\n",
    "problem1_wind_velocity_x_coordinate = problem1_wind_direction_x_coordinate * problem1_wind_speed\n",
    "problem1_wind_velocity_y_coordinate = problem1_wind_direction_y_coordinate * problem1_wind_speed\n",
    "\n",
    "# 3. Calculate the average wind velocity\n",
    "problem1_average_wind_velocity_x_coordinate = np.mean(problem1_wind_velocity_x_coordinate)\n",
    "problem1_average_wind_velocity_y_coordinate = np.mean(problem1_wind_velocity_y_coordinate)\n",
    "\n",
    "# Convert average wind velocity vector back to direction in degrees\n",
    "mean_velocity_angle = np.arctan2(\n",
    "    problem1_average_wind_velocity_y_coordinate,\n",
    "    problem1_average_wind_velocity_x_coordinate\n",
    ")\n",
    "# Adjust angle to compass bearing\n",
    "problem1_average_wind_velocity_angle_degrees = (90 - np.degrees(mean_velocity_angle)) % 360\n",
    "\n",
    "# Calculate the average of the wind directions from the data\n",
    "problem1_average_wind_direction_angle_degrees = np.mean(problem1_wind_direction)\n",
    "\n",
    "# Check if the two average angles are the same\n",
    "problem1_same_angle = np.isclose(\n",
    "    problem1_average_wind_velocity_angle_degrees,\n",
    "    problem1_average_wind_direction_angle_degrees\n",
    ")\n",
    "\n",
    "# 4. Calculate the empirical covariance matrix\n",
    "problem1_wind_velocity_covariance_matrix = np.cov(\n",
    "    np.vstack((\n",
    "        problem1_wind_velocity_x_coordinate,\n",
    "        problem1_wind_velocity_y_coordinate\n",
    "    ))\n",
    ")\n",
    "\n",
    "# Analyze the data\n",
    "# Since the wind is a vector quantity, averaging the wind velocity vectors gives a different result\n",
    "# compared to averaging the wind directions directly due to the circular nature of angles.\n",
    "# The covariance matrix provides insights into the variability and correlation of wind components.\n",
    "\n",
    "# Print the variables\n",
    "print(\"Wind Direction (degrees):\", problem1_wind_direction)\n",
    "print(\"Wind Speed (m/s):\", problem1_wind_speed)\n",
    "print(\"Wind Direction X Coordinate:\", problem1_wind_direction_x_coordinate)\n",
    "print(\"Wind Direction Y Coordinate:\", problem1_wind_direction_y_coordinate)\n",
    "print(\"Wind Velocity X Coordinate:\", problem1_wind_velocity_x_coordinate)\n",
    "print(\"Wind Velocity Y Coordinate:\", problem1_wind_velocity_y_coordinate)\n",
    "print(\"Average Wind Velocity X Coordinate:\", problem1_average_wind_velocity_x_coordinate)\n",
    "print(\"Average Wind Velocity Y Coordinate:\", problem1_average_wind_velocity_y_coordinate)\n",
    "print(\"Average Wind Velocity Angle (degrees):\", problem1_average_wind_velocity_angle_degrees)\n",
    "print(\"Average Wind Direction Angle (degrees):\", problem1_average_wind_direction_angle_degrees)\n",
    "print(\"Are the average angles the same?\", problem1_same_angle)\n",
    "print(\"Wind Velocity Covariance Matrix:\\n\", problem1_wind_velocity_covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 2 - Part 1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data into a dataframe\n",
    "file_path = \"D:\\\\Data Science LAB\\\\data\\\\indoor_train.csv\"\n",
    "df_train = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure of the data\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 2 - Part 2\n",
    "import numpy as np\n",
    "\n",
    "# Extract features and target arrays\n",
    "Xtrain = df_train[['Position X', 'Position Y', 'Position Z']].to_numpy(dtype=np.float64)\n",
    "Ytrain = df_train['Location'].to_numpy(dtype=np.int64)\n",
    "\n",
    "# Check the shapes and dtypes\n",
    "Xtrain_shape = Xtrain.shape\n",
    "Ytrain_shape = Ytrain.shape\n",
    "Xtrain_dtype = Xtrain.dtype\n",
    "Ytrain_dtype = Ytrain.dtype\n",
    "\n",
    "Xtrain_shape, Ytrain_shape, Xtrain_dtype, Ytrain_dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 2 - Part 3\n",
    "# Display column names to verify exact naming\n",
    "df_train.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 2 - Part 4\n",
    "# Correcting the column name for 'Position Y' and re-extracting features and target arrays\n",
    "Xtrain = df_train[['Position X', ' Position Y', 'Position Z']].to_numpy(dtype=np.float64)\n",
    "Ytrain = df_train['Location'].to_numpy(dtype=np.int64)\n",
    "\n",
    "# Confirm the shapes and dtypes\n",
    "Xtrain_shape, Ytrain_shape, Xtrain_dtype, Ytrain_dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 2 - Part 5\n",
    "# Display the shapes and dtypes of Xtrain and Ytrain directly\n",
    "(Xtrain.shape, Ytrain.shape, Xtrain.dtype, Ytrain.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 2 - Part 6\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train the Support Vector Classifier with linear kernel\n",
    "svc_train = SVC(kernel='linear')\n",
    "svc_train.fit(Xtrain, Ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 2 - All steps\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the data into a dataframe\n",
    "file_path = \"D:\\\\Data Science LAB\\\\data\\\\indoor_train.csv\"\n",
    "df_train = pd.read_csv(file_path)\n",
    "\n",
    "# Create Xtrain and Ytrain numpy arrays\n",
    "\"\"\"Xtrain = df_train[['X', 'Y', 'Z']].to_numpy(dtype=np.float64)\n",
    "Ytrain = df_train['Location'].to_numpy(dtype=np.int64)''\"\n",
    "\"\"\"\n",
    "Xtrain = df_train[['Position X', ' Position Y', 'Position Z']].to_numpy(dtype=np.float64)\n",
    "Ytrain = df_train['Location'].to_numpy(dtype=np.int64)\n",
    "\n",
    "\n",
    "# Train a Support Vector Classifier with linear kernel\n",
    "svc_train = SVC(kernel='linear')\n",
    "svc_train.fit(Xtrain, Ytrain)\n",
    "\n",
    "df_train.head(), Xtrain.shape, Ytrain.shape, svc_train\n",
    "\n",
    "# Check the columns in df_train to identify the correct names\n",
    "df_train.columns\n",
    "\n",
    "# Update column names in the code to match the dataset\n",
    "Xtrain = df_train[['Position X', ' Position Y', 'Position Z']].to_numpy(dtype=np.float64)\n",
    "Ytrain = df_train['Location'].to_numpy(dtype=np.int64)\n",
    "\n",
    "# Train a Support Vector Classifier with linear kernel\n",
    "svc_train = SVC(kernel='linear')\n",
    "svc_train.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Displaying results to verify\n",
    "df_train.head(), Xtrain.shape, Ytrain.shape, svc_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 2 - 2nd solution\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"D:\\\\Data Science LAB\\\\data\\\\indoor_train.csv\"\n",
    "df_train = pd.read_csv(file_path)\n",
    "\n",
    "# Create numpy arrays for features and labels\n",
    "Xtrain = df_train[['Position X', ' Position Y', 'Position Z']].to_numpy(dtype=np.float64)\n",
    "Ytrain = df_train['Location'].to_numpy(dtype=np.int64)\n",
    "\n",
    "# Train the SVM model\n",
    "svc_train = SVC(kernel='linear')\n",
    "svc_train.fit(Xtrain, Ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 , Problem 3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "file_path = \"D:\\\\Data Science LAB\\\\data\\\\spam.csv\"\n",
    "#data = pd.read_csv(file_path)\n",
    "#data = pd.read_csv(file_path, encoding='utf-8', errors='replace')\n",
    "data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "\n",
    "# Assuming the data contains columns \"free\", \"prize\", \"win\" for the features and \"spam\" for the target\n",
    "# Adjust if the column names differ in the actual data\n",
    "problem3_X = data[['free', 'prize', 'win']].values  # Shape (n_texts, 3)\n",
    "problem3_Y = data['spam'].values  # Shape (n_texts,)\n",
    "\n",
    "# Split data into train, calibration, and test sets (40%, 20%, 40%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(problem3_X, problem3_Y, test_size=0.6, random_state=42)\n",
    "X_calib, X_test, y_calib, y_test = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42)\n",
    "\n",
    "\n",
    "from scipy.special import expit  # Sigmoid function\n",
    "\n",
    "class ProportionalSpam:\n",
    "    def __init__(self, beta_0=0, beta=None):\n",
    "        self.beta_0 = beta_0\n",
    "        self.beta = beta if beta is not None else np.zeros(3)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Logistic function G(beta_0 + beta . X)\n",
    "        return expit(self.beta_0 + np.dot(X, self.beta))\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        # Calculate the logistic loss\n",
    "        probas = self.predict_proba(X)\n",
    "        return -np.mean(y * np.log(probas + 1e-15) + (1 - y) * np.log(1 - probas + 1e-15))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Train logistic regression model\n",
    "problem3_ps = ProportionalSpam()\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "problem3_ps.beta_0 = logistic_model.intercept_[0]\n",
    "problem3_ps.beta = logistic_model.coef_[0]\n",
    "\n",
    "# Predict on calibration data\n",
    "problem3_X_pred = problem3_ps.predict_proba(X_calib).reshape(-1, 1)\n",
    "\n",
    "# Train calibration model\n",
    "problem3_calibrator = DecisionTreeRegressor()\n",
    "problem3_calibrator.fit(problem3_X_pred, y_calib)\n",
    "\n",
    "# Get logistic regression predictions on test set\n",
    "test_preds = problem3_ps.predict_proba(X_test).reshape(-1, 1)\n",
    "\n",
    "# Use the calibrator to adjust the probabilities\n",
    "problem3_final_predictions = problem3_calibrator.predict(test_preds)\n",
    "\n",
    "# Check column names to verify they match expected structure\n",
    "print(data.columns)\n",
    "\n",
    "# Create new columns based on keyword presence in the 'v2' column (adjust if necessary)\n",
    "data['free'] = data['v2'].str.contains(r'\\bfree\\b', case=False, na=False).astype(int)\n",
    "data['prize'] = data['v2'].str.contains(r'\\bprize\\b', case=False, na=False).astype(int)\n",
    "data['win'] = data['v2'].str.contains(r'\\bwin\\b', case=False, na=False).astype(int)\n",
    "\n",
    "# Define the target column based on whether a message is spam or not\n",
    "data['spam'] = (data['v1'] == 'spam').astype(int)\n",
    "\n",
    "# Define features and target arrays\n",
    "problem3_X = data[['free', 'prize', 'win']].values  # Shape (n_texts, 3)\n",
    "problem3_Y = data['spam'].values  # Shape (n_texts,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment 3 - Problem 1 - Solution whole\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the file and extract wind-direction and wind-speed as numpy arrays\n",
    "wind_direction = []\n",
    "wind_speed = []\n",
    "\n",
    "with open(r'D:\\Data Science LAB\\data\\smhi.csv', 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    fieldnames = reader.fieldnames\n",
    "    print(\"Available columns:\", reader.fieldnames)\n",
    "    # Find the column names for wind direction and wind speed\n",
    "    for name in fieldnames:\n",
    "        if 'Vindriktning' in name:\n",
    "            wind_direction_column = name\n",
    "        if 'Vindhastighet' in name:\n",
    "            wind_speed_column = name\n",
    "\n",
    "    # Now, read the data\n",
    "    for row in reader:\n",
    "        # Get the wind direction and speed\n",
    "        #direction = row[wind_direction_column]\n",
    "        #speed = row[wind_speed_column]\n",
    "        wind_direction_column = 'wind_direction'  # Replace with the actual column name from the CSV file\n",
    "        wind_speed_column = 'wind_speed'          # Replace with the actual column name from the CSV file\n",
    "\n",
    "        # Handle missing or invalid data\n",
    "        try:\n",
    "            wind_direction.append(float(direction))\n",
    "            wind_speed.append(float(speed))\n",
    "        except ValueError:\n",
    "            continue  # skip rows with invalid data\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "wind_direction = np.array(wind_direction)\n",
    "wind_speed = np.array(wind_speed)\n",
    "\n",
    "# Step 2: Convert wind-direction into points on the unit circle\n",
    "# Convert wind_direction to radians\n",
    "theta_rad = np.deg2rad(wind_direction)\n",
    "\n",
    "# Compute unit circle coordinates (direction TO which wind is going)\n",
    "x_coordinate = -np.cos(theta_rad)\n",
    "y_coordinate = -np.sin(theta_rad)\n",
    "\n",
    "# Construct wind-velocity vector components\n",
    "wind_velocity_x = wind_speed * x_coordinate\n",
    "wind_velocity_y = wind_speed * y_coordinate\n",
    "\n",
    "# Step 3: Calculate the average wind velocity and convert it back to direction\n",
    "avg_wind_velocity_x = np.mean(wind_velocity_x)\n",
    "avg_wind_velocity_y = np.mean(wind_velocity_y)\n",
    "\n",
    "avg_wind_speed = np.sqrt(avg_wind_velocity_x**2 + avg_wind_velocity_y**2)\n",
    "\n",
    "avg_wind_direction_rad = np.arctan2(avg_wind_velocity_y, avg_wind_velocity_x)\n",
    "avg_wind_direction_deg = np.rad2deg(avg_wind_direction_rad)\n",
    "# Wind direction FROM which wind is coming\n",
    "avg_wind_direction_deg_from = (avg_wind_direction_deg + 180) % 360\n",
    "\n",
    "print(f\"Average wind speed: {avg_wind_speed:.2f} m/s\")\n",
    "print(f\"Average wind direction (from): {avg_wind_direction_deg_from:.2f} degrees\")\n",
    "\n",
    "# Compute the circular mean of wind_direction\n",
    "theta_rad = np.deg2rad(wind_direction)\n",
    "mean_x = np.mean(np.cos(theta_rad))\n",
    "mean_y = np.mean(np.sin(theta_rad))\n",
    "mean_direction_rad = np.arctan2(mean_y, mean_x)\n",
    "mean_direction_deg = np.rad2deg(mean_direction_rad)\n",
    "mean_direction_deg = mean_direction_deg % 360\n",
    "\n",
    "print(f\"Circular mean of wind direction: {mean_direction_deg:.2f} degrees\")\n",
    "\n",
    "# Step 4: Calculate the empirical covariance matrix\n",
    "wind_velocity = np.vstack((wind_velocity_x, wind_velocity_y))\n",
    "covariance_matrix = np.cov(wind_velocity)\n",
    "\n",
    "print(\"Empirical covariance matrix:\")\n",
    "print(covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment 3 - Problem 2 - Solution whole\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 1. Load 'indoor_train.csv' into a dataframe df_train\n",
    "df_train = pd.read_csv('data/indoor_train.csv')\n",
    "\n",
    "# 2. From df_train, create Xtrain and Ytrain\n",
    "Xtrain = df_train[['X', 'Y', 'Z']].values.astype('float64')\n",
    "Ytrain = df_train['Location'].values.astype('int64')\n",
    "\n",
    "# Verify the shapes and data types\n",
    "assert Xtrain.shape == (1154, 3)\n",
    "assert Ytrain.shape == (1154,)\n",
    "assert Xtrain.dtype == np.float64\n",
    "assert Ytrain.dtype == np.int64\n",
    "\n",
    "# 3. Train a Support Vector Classifier with kernel='linear'\n",
    "svc_train = SVC(kernel='linear')\n",
    "svc_train.fit(Xtrain, Ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment 3 - Problem 3 - Solution whole\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Step 1: Load 'data/spam.csv' and create problem3_X and problem3_Y\n",
    "\n",
    "# Read the CSV file\n",
    "#data = pd.read_csv('D:\\Data Science LAB\\data\\spam.csv')\n",
    "#data = pd.read_csv(r'D:\\Data Science LAB\\data\\spam.csv', encoding='utf-8', errors='ignore')\n",
    "data = pd.read_csv(r'D:\\Data Science LAB\\data\\spam.csv', encoding='latin1')\n",
    "\n",
    "#D:\\Data Science LAB\\data\n",
    "\n",
    "# Define the words to check for presence\n",
    "words = ['free', 'prize', 'win']\n",
    "\n",
    "# Initialize a list to store features\n",
    "features = []\n",
    "\n",
    "# Loop over each text in the dataset\n",
    "for text in data['text']:\n",
    "    text_lower = text.lower()\n",
    "    # Check for presence of each word and create a feature vector\n",
    "    feature_vector = [1 if word in text_lower else 0 for word in words]\n",
    "    features.append(feature_vector)\n",
    "\n",
    "# Convert the list of features to a NumPy array\n",
    "problem3_X = np.array(features)\n",
    "\n",
    "# Extract the labels (spam or not spam) as a NumPy array\n",
    "problem3_Y = data['spam'].values\n",
    "\n",
    "# Split the data into train (40%), calibration (20%), and test (40%) sets\n",
    "# Shuffle the data first\n",
    "np.random.seed(42)\n",
    "indices = np.arange(len(problem3_X))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Shuffle the features and labels\n",
    "X_shuffled = problem3_X[indices]\n",
    "y_shuffled = problem3_Y[indices]\n",
    "\n",
    "# Calculate the sizes for each split\n",
    "n_samples = len(problem3_X)\n",
    "train_size = int(0.4 * n_samples)\n",
    "calib_size = int(0.2 * n_samples)\n",
    "test_size = n_samples - train_size - calib_size\n",
    "\n",
    "# Split the data accordingly\n",
    "X_train = X_shuffled[:train_size]\n",
    "y_train = y_shuffled[:train_size]\n",
    "\n",
    "X_calib = X_shuffled[train_size:train_size + calib_size]\n",
    "y_calib = y_shuffled[train_size:train_size + calib_size]\n",
    "\n",
    "X_test = X_shuffled[train_size + calib_size:]\n",
    "y_test = y_shuffled[train_size + calib_size:]\n",
    "\n",
    "# Step 2: Implement the ProportionalSpam class with the logistic regression loss function\n",
    "\n",
    "class ProportionalSpam:\n",
    "    def __init__(self, learning_rate=0.1, num_iterations=1000):\n",
    "        # Initialize parameters\n",
    "        self.beta0 = 0.0\n",
    "        self.beta = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        # Initialize weights\n",
    "        self.beta = np.zeros(n_features)\n",
    "        self.beta0 = 0.0\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            # Compute the linear combination\n",
    "            linear_model = np.dot(X, self.beta) + self.beta0\n",
    "            # Apply the logistic function\n",
    "            y_pred = 1 / (1 + np.exp(-linear_model))\n",
    "\n",
    "            # Compute gradients\n",
    "            dbeta = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            dbeta0 = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            # Update parameters\n",
    "            self.beta -= self.learning_rate * dbeta\n",
    "            self.beta0 -= self.learning_rate * dbeta0\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Compute the linear combination\n",
    "        linear_model = np.dot(X, self.beta) + self.beta0\n",
    "        # Return probabilities using the logistic function\n",
    "        return 1 / (1 + np.exp(-linear_model))\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Get predicted probabilities\n",
    "        proba = self.predict_proba(X)\n",
    "        # Return class predictions based on threshold 0.5\n",
    "        return np.where(proba >= 0.5, 1, 0)\n",
    "\n",
    "    def loss_function(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        # Compute the linear combination\n",
    "        linear_model = np.dot(X, self.beta) + self.beta0\n",
    "        # Apply the logistic function\n",
    "        y_pred = 1 / (1 + np.exp(-linear_model))\n",
    "        # Compute the logistic regression loss\n",
    "        loss = - (1 / n_samples) * np.sum(\n",
    "            y * np.log(y_pred + 1e-15) + (1 - y) * np.log(1 - y_pred + 1e-15)\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "# Example Test Cell to check loss function (you can ignore this if not required)\n",
    "# problem3_ps_test = ProportionalSpam()\n",
    "# problem3_ps_test.fit(X_train, y_train)\n",
    "# print(\"Loss on training data:\", problem3_ps_test.loss_function(X_train, y_train))\n",
    "\n",
    "# Step 3: Train the model problem3_ps on the training data\n",
    "problem3_ps = ProportionalSpam(learning_rate=0.1, num_iterations=1000)\n",
    "problem3_ps.fit(X_train, y_train)\n",
    "\n",
    "# Create problem3_X_pred with predictions on the calibration dataset\n",
    "problem3_X_pred = problem3_ps.predict_proba(X_calib).reshape(-1, 1)\n",
    "\n",
    "# Train a calibration model using DecisionTreeRegressor\n",
    "problem3_calibrator = DecisionTreeRegressor()\n",
    "problem3_calibrator.fit(problem3_X_pred, y_calib)\n",
    "\n",
    "# Step 4: Make final predictions on the testing data\n",
    "# Get initial predictions from the trained model\n",
    "test_proba = problem3_ps.predict_proba(X_test).reshape(-1, 1)\n",
    "\n",
    "# Apply the calibrator to get final predictions\n",
    "problem3_final_predictions = problem3_calibrator.predict(test_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Data Science and Data Engineering/Semester 1/Period 2/Introduction to Data Science/Data Science LAB/data/data/smhi.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the file without altering it\u001b[39;00m\n\u001b[0;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/Data Science and Data Engineering/Semester 1/Period 2/Introduction to Data Science/Data Science LAB/data/data/smhi.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Extract wind direction and wind speed as numpy arrays (full dataset)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m problem1_wind_direction \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVindriktning\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[1;32mc:\\Users\\Debashish Sen\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Debashish Sen\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Debashish Sen\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\Debashish Sen\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Debashish Sen\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Data Science and Data Engineering/Semester 1/Period 2/Introduction to Data Science/Data Science LAB/data/data/smhi.csv'"
     ]
    }
   ],
   "source": [
    "#Assignment 3-1 another solution\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the file without altering it\n",
    "file_path = '/mnt/data/smhi.csv'\n",
    "data = pd.read_csv(file_path, sep=';', skiprows=10)\n",
    "\n",
    "# Extract wind direction and wind speed as numpy arrays (full dataset)\n",
    "problem1_wind_direction = data['Vindriktning'].astype(float).to_numpy()\n",
    "problem1_wind_speed = data['Vindhastighet'].astype(float).to_numpy()\n",
    "\n",
    "# Convert wind direction to radians\n",
    "wind_direction_rad = np.radians(problem1_wind_direction)\n",
    "\n",
    "# Calculate wind direction x and y coordinates on the unit circle\n",
    "problem1_wind_direction_x_coordinate = np.cos(wind_direction_rad)\n",
    "problem1_wind_direction_y_coordinate = np.sin(wind_direction_rad)\n",
    "\n",
    "# Calculate wind velocity components\n",
    "problem1_wind_velocity_x_coordinate = problem1_wind_speed * problem1_wind_direction_x_coordinate\n",
    "problem1_wind_velocity_y_coordinate = problem1_wind_speed * problem1_wind_direction_y_coordinate\n",
    "\n",
    "# Calculate the average wind velocity components\n",
    "problem1_average_wind_velocity_x_coordinate = np.mean(problem1_wind_velocity_x_coordinate)\n",
    "problem1_average_wind_velocity_y_coordinate = np.mean(problem1_wind_velocity_y_coordinate)\n",
    "\n",
    "# Calculate the angle of the average wind velocity vector in degrees\n",
    "problem1_average_wind_velocity_angle_degrees = np.degrees(\n",
    "    np.arctan2(problem1_average_wind_velocity_y_coordinate, problem1_average_wind_velocity_x_coordinate)\n",
    ")\n",
    "\n",
    "# Calculate the average angle of the wind direction in degrees\n",
    "problem1_average_wind_direction_angle_degrees = np.mean(problem1_wind_direction)\n",
    "\n",
    "# Compare if the angles are the same\n",
    "problem1_same_angle = np.isclose(problem1_average_wind_velocity_angle_degrees, problem1_average_wind_direction_angle_degrees)\n",
    "\n",
    "# Calculate the covariance matrix of wind velocity components\n",
    "problem1_wind_velocity_covariance_matrix = np.cov(\n",
    "    np.vstack((problem1_wind_velocity_x_coordinate, problem1_wind_velocity_y_coordinate))\n",
    ")\n",
    "\n",
    "# Display results for verification\n",
    "print(\"problem1_wind_direction:\", problem1_wind_direction)\n",
    "print(\"problem1_wind_speed:\", problem1_wind_speed)\n",
    "print(\"problem1_wind_direction_x_coordinate:\", problem1_wind_direction_x_coordinate)\n",
    "print(\"problem1_wind_direction_y_coordinate:\", problem1_wind_direction_y_coordinate)\n",
    "print(\"problem1_wind_velocity_x_coordinate:\", problem1_wind_velocity_x_coordinate)\n",
    "print(\"problem1_wind_velocity_y_coordinate:\", problem1_wind_velocity_y_coordinate)\n",
    "print(\"problem1_average_wind_velocity_x_coordinate:\", problem1_average_wind_velocity_x_coordinate)\n",
    "print(\"problem1_average_wind_velocity_y_coordinate:\", problem1_average_wind_velocity_y_coordinate)\n",
    "print(\"problem1_average_wind_velocity_angle_degrees:\", problem1_average_wind_velocity_angle_degrees)\n",
    "print(\"problem1_average_wind_direction_angle_degrees:\", problem1_average_wind_direction_angle_degrees)\n",
    "print(\"problem1_same_angle:\", problem1_same_angle)\n",
    "print(\"problem1_wind_velocity_covariance_matrix:\")\n",
    "print(problem1_wind_velocity_covariance_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
